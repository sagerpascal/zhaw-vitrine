<!doctype html>
<html lang="en" prefix="og: http://ogp.me/ns#">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="manifest" href="manifest.json"/>

    <!-- CLEAN MARKUP = GOOD KARMA.
      Hi source code lover,

      you're a curious person and a fast learner ;)
      Let's make something beautiful together. Contribute on Github:
      https://github.com/webslides/webslides

      Thanks!
      -->

    <!-- SEO -->
    <title>WebSlides Landings: Create your web presence easily</title>
    <meta name="description"
          content="WebSlides is the easiest way to create HTML presentations and landings. 120+ free slides ready to use.">

    <!-- URL CANONICAL -->
    <!-- <link rel="canonical" href="http://your-url.com/permalink"> -->

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,700,700i%7CMaitree:200,300,400,600,700&amp;subset=latin-ext"
          rel="stylesheet">

    <!-- CSS Base -->
    <link rel="stylesheet" type='text/css' media='all' href="webslides/static/css/webslides.css">

    <!-- Optional - CSS SVG Icons (Font Awesome) -->
    <link rel="stylesheet" type="text/css" media="all" href="webslides/static/css/svg-icons.css">

    <!-- SOCIAL CARDS (ADD YOUR INFO) -->

    <!-- FAVICONS -->
    <link rel="shortcut icon" sizes="16x16" href="../webslides/static/images/favicons/favicon.png">
    <link rel="shortcut icon" sizes="32x32" href="../webslides/static/images/favicons/favicon-32.png">
    <link rel="apple-touch-icon icon" sizes="76x76" href="../webslides/static/images/favicons/favicon-76.png">
    <link rel="apple-touch-icon icon" sizes="120x120" href="../webslides/static/images/favicons/favicon-120.png">
    <link rel="apple-touch-icon icon" sizes="152x152" href="../webslides/static/images/favicons/favicon-152.png">
    <link rel="apple-touch-icon icon" sizes="180x180" href="../webslides/static/images/favicons/favicon-180.png">
    <link rel="apple-touch-icon icon" sizes="192x192" href="../webslides/static/images/favicons/favicon-192.png">

    <!-- Android -->
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="theme-color" content="#333333">
</head>
<body>
<header role="banner">
    <
    <nav role="navigation">
        This presentation was developed by Pascal Sager and ZHAW's Center for AI.
        <ul>
            <li class="linkedin">
                <a rel="external" href="https://www.linkedin.com/in/pascal-sager-3b7403168/" title="LinkedIn">
                    <svg class="fa-linkedin">
                        <use xlink:href="#fa-linkedin"></use>
                    </svg>
                    <em>Pascal Sager</em>
                </a>
            </li>
            <li class="github">
                <a rel="external" href="https://github.com/sagerpascal" title="Github">
                    <svg class="fa-github">
                        <use xlink:href="#fa-github"></use>
                    </svg>
                    <em>sagerpascal</em>
                </a>
            </li>
            <li class="website">
                <a rel="external" href="https://sagerpascal.github.io" title="Github">
                    <svg class="fa-globe">
                        <use xlink:href="#fa-globe"></use>
                    </svg>
                    <em>sagerpascal</em>
                </a>
            </li>
            <!--  <li class="dribbble"><a rel="external" href="http://dribbble.com/webslides" title="Dribbble"><svg class="fa-dribbble"><use xlink:href="#fa-dribbble"></use></svg> <em>webslides</em></a></li> -->
        </ul>
    </nav>
</header>
<main role="main">
    <article id="webslides">

        <!-- Quick Guide
          - Each parent <section> in the <article id="webslides"> element is an individual slide.
          - Vertical sliding = <article id="webslides" class="vertical">
          - <div class="wrap"> = container 90% / <div class="wrap size-50"> = 45%;
        -->

        <section class="fullscreen">
            <div class="card-30">
                <figure>
                    <img src="webslides/static/images/furhat.jpg" alt="Furhat">
                    <figcaption>
                        <a href="https://furhatrobotics.com" title="Furhat Robotics">
                            <svg class="fa-camera">
                                <use xlink:href="#fa-globe"></use>
                            </svg>
                            Furhat Robotics
                        </a>
                    </figcaption>
                </figure>
                <!-- end figure-->
                <div class="flex-content">
                    <h2>1. Furhat Robot</h2>
                    <p class="text-intro">A social robot for research and innovation by Furhat Robotics</p>
                    <p>The Furhat robot consists of a base containing a loudspeaker on which a movable head is mounted.
                        A projector is embedded in the articulated head, which projects a face onto a translucent
                        frosted glass surface. Through this mechanism, the robot is able to project different facial
                        expressions by dynamically manipulating the eyes and mouth to simulate the appearance of speech.
                    </p>
                    <p>The ZHAW Cetre for AI used this robot for research in the field of human-robot interaction.
                        Today, it is primary used in educational settings, serving to elucidate to a diverse audience
                        the principles of artificial intelligence, encompassing the functioning of technologies like
                        speech-to-text, text-to-speech, and natural language understanding.
                    </p>
                </div>
                <!-- end .flex-content-->
            </div>
            <!-- end .card-50-->
        </section>

        <section class="fullscreen">
            <div class="card-30">
                <figure>
                    <img src="webslides/static/images/eeg.jpg" alt="EEG">
                    <figcaption>
                        <a href="https://furhatrobotics.com" title="EEG Headset">
                            <svg class="fa-camera">
                                <use xlink:href="#fa-globe"></use>
                            </svg>
                            EEG Headset
                        </a>
                    </figcaption>
                </figure>
                <!-- end figure-->
                <div class="flex-content">
                    <h2>2. Electroencephalography</h2>
                    <p class="text-intro">Electroencephalography (EEG) is a non-invasive neuroimaging technique that
                        measures the electrical activity of the brain through electrodes placed on the scalp.</p>
                    <p>EEG records the collective neural signals, providing insights into brain function and
                        dynamics in real-time. In the realm of artificial intelligence (AI), EEG holds significant
                        promise for applications ranging from brain-computer interfaces to cognitive computing.
                        Researchers leverage EEG data to decode mental states, assess cognitive workload, and even
                        control devices through brain signals. The integration of EEG with AI algorithms enables the
                        development of innovative solutions for neurofeedback, mental health monitoring, and
                        enhancing human-machine interactions. By bridging the gap between neuroscience and AI, EEG
                        contributes to the advancement of technologies that can understand and respond to human
                        cognitive processes, paving the way for new possibilities in healthcare, gaming, and
                        beyond.
                    </p>
                </div>
                <!-- end .flex-content-->
            </div>
            <!-- end .card-30-->
        </section>

        <section class="fullscreen">
            <div class="card-30">
                <figure>
                    <img src="webslides/static/images/dgx-a100.jpg" alt="gpu">
                    <figcaption>
                        <a href="https://furhatrobotics.com" title="Nvidia DGX A-100">
                            <svg class="fa-camera">
                                <use xlink:href="#fa-globe"></use>
                            </svg>
                            Nvidia DGX A-100
                        </a>
                    </figcaption>
                </figure>
                <!-- end figure-->
                <div class="flex-content">
                    <h2>3. Graphics Processing Units</h2>
                    <p class="text-intro">Graphics Processing Units (GPUs) have become indispensable in the realm of
                        artificial
                        intelligence (AI), playing a pivotal role in accelerating computational tasks essential for
                        training and inference processes.</p>
                    <p> Unlike traditional CPUs, GPUs are
                        specifically designed to handle parallel processing, making them highly efficient for the
                        parallelized nature of many AI algorithms. The parallel architecture of GPUs allows them to
                        simultaneously execute multiple operations, significantly speeding up the training of deep
                        neural networks</p>
                    <p>The ZHAW's Centre for AI manages a high-end GPU cluster, including H-100, A-100, and V-100 GPUs
                        from Nvidia.</p>
                </div>
                <!-- end .flex-content-->
            </div>
            <!-- end .card-30-->
        </section>

        <section class="fullscreen">
            <div class="card-30">
                <figure>
                    <img src="webslides/static/images/wheel_bearing.jpg" alt="gpu">
                    <figcaption>
                        <a href="https://furhatrobotics.com" title="Wheel Bearing">
                            <svg class="fa-camera">
                                <use xlink:href="#fa-globe"></use>
                            </svg>
                            Wheel Bearing
                        </a>
                    </figcaption>
                </figure>
                <!-- end figure-->
                <div class="flex-content">
                    <h2>4. Predictive Maintenance</h2>
                    <p class="text-intro">Predictive maintenance leverages the power of artificial intelligence to
                        revolutionize the
                        way industries manage and maintain their equipment.</p>
                    <p> By employing advanced algorithms and
                        machine learning models, AI analyzes historical data, sensor readings, and operational
                        parameters to predict potential equipment failures before they occur. This proactive
                        approach allows organizations to schedule maintenance activities precisely when needed,
                        reducing downtime, minimizing costly unplanned outages, and optimizing resource
                        utilization. </p>
                    <p>One application of predictive maintenance is to analyze the driving and braking behavior in
                        order to detect damage to the wheel bearing at an early stage.</p>
                </div>
                <!-- end .flex-content-->
            </div>
            <!-- end .card-30-->
        </section>

        <section class="fullscreen">
            <div class="card-30">
                <figure>
                    <img src="webslides/static/images/books.jpg" alt="book">
                    <figcaption>
                        <a href="https://furhatrobotics.com" title="Book">
                            <svg class="fa-camera">
                                <use xlink:href="#fa-globe"></use>
                            </svg>
                            Books by CAI
                        </a>
                    </figcaption>
                </figure>
                <!-- end figure-->
                <div class="flex-content">
                    <h2>5. Books</h2>
                    <p class="text-intro">Our researchers have contributed to various literature to share their
                        insights.</p>
                    <p>
                        While there is an abundance of literature on Data Science, there is a lack of focus on its
                        applied side.
                        Data Science is a discipline that integrates various established research fields, and its
                        essence lies in creating synergies to develop efficient data products for both academic and
                        industrial projects.
                        We aim to provide real-world insights into Data Science by showcasing its deployment in
                        data-intensive projects, sharing experiences, and drawing lessons.
                        The book "Applied Data Science" is positioned as complementary to theoretical textbooks,
                        offering a "big picture", enabling readers to delve into practical Data Science applications,
                        including collaborative efforts between academia and industry experts detailing technology
                        transfer in real-world scenarios.
                    </p>
                </div>
                <!-- end .flex-content-->
            </div>
            <!-- end .card-30-->
        </section>

        <section class="fullscreen">
            <div class="card-30">
                <figure>
                    <img src="webslides/static/images/makeblock.jpg" alt="book">
                    <figcaption>
                        <a href="https://furhatrobotics.com" title="MakeBlock Robot">
                            <svg class="fa-camera">
                                <use xlink:href="#fa-globe"></use>
                            </svg>
                            MakeBlock Robot
                        </a>
                    </figcaption>
                </figure>
                <!-- end figure-->
                <div class="flex-content">
                    <h2>6. Autonomous Robots</h2>
                    <p class="text-intro">We use AI to train autonomous robot system.</p>
                    <p>
                        Artificial Intelligence plays a crucial role in enabling autonomous systems to navigate using
                        cameras. Through computer vision algorithms, AI empowers these systems to interpret visual
                        information captured by cameras and make informed decisions in real-time. The AI can analyze the
                        camera feed to identify and understand the environment, recognize objects, detect obstacles, and
                        estimate distances. This information is then processed to generate navigation commands, allowing
                        the autonomous system to adjust its path and avoid collisions.
                    </p>
                </div>
                <!-- end .flex-content-->
            </div>
            <!-- end .card-30-->
        </section>


        <section class="bg-black">
            <div class="wrap">
                <div class="slide-bottom content-center">
                    In standby to save energy
                </div>
            </div>
        </section>

        <section class="bg-white">
            <div class="wrap">
                <div class="grid">
                    <div class="column">
                        <h3>Gesture Control</h3>
                        <p>Open and close your hand to navigate between pages.</p>
                        <figure>
                            <img src="webslides/static/images/hand.jpeg" alt="hand gestures">
                        </figure>
                    </div>
                    <div class="column content-center">
                        <canvas id="canvas" class="border canvasbox" style="margin: auto"></canvas>
                    </div>
                </div>
            </div>

        </section>

        <video class="videobox canvasbox" autoplay="autoplay" id="myvideo" style="visibility: hidden"></video>


    </article>
</main>
<!--main-->

<style>
    .canvasbox {
        border-radius: 3px;
        margin-right: 10px;
        width: 450px;
        height: 338px;
        border-bottom: 3px solid #0063FF;
        box-shadow: 0 2px 3px 0 rgba(0, 0, 0, 0.2), 0 4px 10px 0 #00000030;
        background: #333;

    }
</style>

<!-- Required -->
<script src="webslides/static/js/webslides.js"></script>
<script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"></script>

<script>

    if ('serviceWorker' in navigator) {
        window.addEventListener('load', function () {
            navigator.serviceWorker.register('service-worker.js');
        });
    }


    // SEE: https://codepen.io/victordibia/pen/RdWbEY
    const video = document.getElementById("myvideo");
    const canvas = document.getElementById("canvas");
    const context = canvas.getContext("2d");
    let model = null;
    let lastFace = null;
    let lastOpen = null;
    let lastClose = null;
    let openCount = 0;
    let closeCount = 0;
    let closeDetected = false;
    let openDetected = false;
    window.ws = new WebSlides();
    const standbySlide = 6;
    const videoSlide = 7;

    const modelParams = {
        flipHorizontal: true,   // flip e.g for video
        maxNumBoxes: 20,        // maximum number of boxes to detect
        iouThreshold: 0.5,      // ioU threshold for non-max suppression
        scoreThreshold: 0.6,    // confidence threshold for predictions.
    }


    function runDetection() {
        model.detect(video).then(predictions => {
            for (p in predictions) {
                if (predictions[p].label === "face") {
                    if (lastFace === null || new Date() - lastFace > 60000) {
                        window.ws.goToSlide(videoSlide);
                    }
                    lastFace = new Date();
                }
                if (predictions[p].label === "open") {
                    if (new Date() - lastOpen > 3000) {
                        openCount = 0;
                    }
                    lastOpen = new Date();
                    openCount++;

                    if (openCount > 4) {
                        openDetected = true;
                    }
                }
                if (predictions[p].label === "closed") {
                    if (new Date() - lastClose > 3000) {
                        closeCount = 0;
                    }
                    lastClose = new Date();

                    if (openDetected) {
                        closeCount++;
                    }

                    if (closeCount > 4) {
                        closeDetected = true;
                    }
                }

                if (new Date() - lastOpen > 6000) {
                    openDetected = false;
                    closeDetected = false;
                    closeCount = 0;
                    openCount = 0;
                    lastOpen = null;
                    lastClose = null;
                    console.log("Resetting");
                }

                if (openDetected && closeDetected) {
                    console.log("Open and close detected");
                    openDetected = false;
                    closeDetected = false;
                    closeCount = 0;
                    openCount = 0;
                    lastOpen = null;
                    lastClose = null;
                    updateSlide();
                }

            }
            model.renderPredictions(predictions, canvas, context, video);
            requestAnimationFrame(runDetection);
        });
    }

    handTrack.load(modelParams).then(lmodel => {
        model = lmodel
    });

    handTrack.startVideo(video).then(function (status) {
        console.log("video started", status);
        if (status) {
            console.log("Video started. Now tracking");
            runDetection()
        } else {
            console.log("Please enable video");
        }
    });


    function checkValidTime() {
        // Check if valid time, otherwise go to standby
        var d = new Date();
        var hours = d.getHours();
        var mins = d.getMinutes();
        var day = d.getDay();

        return day >= 0
            && day <= 6
            && hours >= 8
            && (hours < 18 || hours === 18 && mins <= 30);
    }

    function updateSlide() {
        if (checkValidTime()) {
            if (window.ws.currentSlide_.i >= standbySlide - 1) {
                window.ws.goToSlide(0);
            } else {
                window.ws.goNext();
            }
        } else {
            window.ws.goToSlide(standbySlide);
        }
    }

    function standby() {
        if (!checkValidTime()) {
            window.ws.goToSlide(standbySlide);
        }
    }

    setInterval(standby, 30000);

</script>

<!-- OPTIONAL - svg-icons.js (fontastic.me - Font Awesome as svg icons) -->
<script defer src="webslides/static/js/svg-icons.js"></script>

</body>
</html>
